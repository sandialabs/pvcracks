{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2953166f-9996-4024-82e6-24ddf3effbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR \n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as mpatches\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# pv_vision_dir = os.path.join(Path.home(), 'pv-vision')\n",
    "pv_vision_dir = os.path.join('/home/eccoope', 'pv-vision')\n",
    "# functions_dir = os.path.join(Path.home(), 'el_img_cracks_ec', 'scripts')\n",
    "functions_dir = os.path.join('/home/eccoope', 'el_img_cracks_ec', 'scripts')\n",
    "\n",
    "sys.path.append(pv_vision_dir)\n",
    "sys.path.append(functions_dir)\n",
    "\n",
    "# ojas_functions_dir = os.path.join(Path.home(), 'pvcracks/retrain/')\n",
    "ojas_functions_dir = \"/home/nrjost/githome/pvcracks/retrain/\"\n",
    "sys.path.append(ojas_functions_dir)\n",
    "\n",
    "from tutorials.unet_model import construct_unet\n",
    "import functions\n",
    "from torch.utils.data import random_split\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "251c8172",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/home/nrjost/githome/pvcracks_dev/retrain/training/Channeled_Combined_CWRU_LBNL_ASU/\"\n",
    "\n",
    "\n",
    "model_weight_paths = {\n",
    "    \"emma_retrained\": \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/retrained_pv-vision_model.pt\",\n",
    "    \"original\": \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/pv-vision_model.pt\",\n",
    "}\n",
    "\n",
    "# weight_path = model_weight_paths[\"emma_retrained\"]\n",
    "weight_path = model_weight_paths[\"original\"]\n",
    "\n",
    "checkpoint_name = root.split(\"/\")[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8b87524",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {0: \"dark\", 1: \"busbar\", 2: \"crack\", 3: \"non-cell\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf350952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(pred, target, epsilon=1e-6):\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum()\n",
    "    dice = (2. * intersection + epsilon) / (union + epsilon)\n",
    "    return dice\n",
    "\n",
    "def iou_score(pred, target, epsilon=1e-6):\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum() - intersection\n",
    "    iou = (intersection + epsilon) / (union + epsilon)\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e5b3df5-d827-4d5d-92a1-2c2fdcbef7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(root):\n",
    "    transformers = functions.Compose([functions.ChanneledFixResize(256), functions.ToTensor(), functions.Normalize()])\n",
    "    \n",
    "    full_dataset = functions.SolarDataset(\n",
    "        root, image_folder=\"img/all\", mask_folder=\"ann/all\", transforms=transformers\n",
    "    )\n",
    "\n",
    "    return full_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97d70c97-24fa-427a-8934-932d695a6040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_device_and_model(weight_path):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # device = torch.device(\"mps\")\n",
    "    unet = construct_unet(len(category_mapping))\n",
    "    unet = torch.nn.DataParallel(unet)\n",
    "    \n",
    "    model = unet.module.to(device)\n",
    "    \n",
    "    return device, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a142ea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_save_dir(base_dir, checkpoint_name):\n",
    "    checkpoint_dir = base_dir + \"/checkpoints/\"\n",
    "    folders = [folder for folder in os.listdir(checkpoint_dir)]\n",
    "    \n",
    "    max_number = 0\n",
    "    for folder in folders:\n",
    "        number = int(folder[-1])\n",
    "        if number > max_number:\n",
    "            max_number = number\n",
    "\n",
    "    new_folder_name = f\"{checkpoint_name}{max_number + 1}\"\n",
    "    new_folder_path = os.path.join(checkpoint_dir, new_folder_name)\n",
    "    \n",
    "    os.makedirs(new_folder_path, exist_ok=True)\n",
    "    \n",
    "    return new_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eab99a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = load_dataset(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "089d575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.9 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "\n",
    "train_subset, test_subset = random_split(full_dataset, [train_size, test_size], generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51dd39d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is needed so that we can a) split the dataset into train/test while ensuring our seed is the same as the wandb_k_fold, b) and preserver stuff like __getraw__ from solardataset when doing inference\n",
    "\n",
    "class SubsetWithRaw(torch.utils.data.Subset):\n",
    "    def __getraw__(self, idx):\n",
    "        return self.dataset.__getraw__(self.indices[idx])\n",
    "\n",
    "train_set = SubsetWithRaw(full_dataset, train_subset.indices)\n",
    "test_set = SubsetWithRaw(full_dataset, test_subset.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d61658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device, model = load_device_and_model(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d889e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def new_inference_and_show(idx, threshold=0.5):\n",
    "    # Get the preprocessed image and multi-hot ground truth mask\n",
    "    img, mask = test_loader.dataset.__getitem__(idx)\n",
    "    img = img.to(device)\n",
    "    \n",
    "    # Get the raw image for display (assuming __getraw__ returns a PIL image)\n",
    "    raw_img, _ = test_loader.dataset.__getraw__(idx)\n",
    "    \n",
    "    # --- Run inference ---\n",
    "    # Get raw logits from the model, then apply Sigmoid and threshold\n",
    "    logits = model(img.unsqueeze(0)).detach().cpu()  # shape: [1, 4, H, W]\n",
    "    probs = torch.sigmoid(logits)                     # shape: [1, 4, H, W]\n",
    "    pred_mask = (probs > threshold).float().squeeze(0).numpy()  # shape: [4, H, W]\n",
    "    \n",
    "    # Ground truth is assumed to be already a 4-channel multi-hot mask.\n",
    "    gt_mask = mask.cpu().numpy()  # shape: [4, H, W]\n",
    "    \n",
    "    # --- Visualization ---\n",
    "    # Create a grid with 3 rows and 4 columns:\n",
    "    #   Row 0: Raw image (displayed only once in the first column)\n",
    "    #   Row 1: Ground truth masks for each class\n",
    "    #   Row 2: Predicted masks for each class\n",
    "    n_classes = len(category_mapping)\n",
    "    class_names = [f'({k}) {v}' for k, v in category_mapping.items()]\n",
    "    \n",
    "    fig, axs = plt.subplots(3, n_classes, figsize=(4*n_classes, 12))\n",
    "    \n",
    "    # Row 0: Display raw image in first subplot; hide other subplots in this row.\n",
    "    axs[0, 0].imshow(raw_img.convert('L'), cmap='viridis')\n",
    "    axs[0, 0].set_title(\"Raw Image\")\n",
    "    axs[0, 0].axis('off')\n",
    "    for j in range(1, n_classes):\n",
    "        axs[0, j].axis('off')\n",
    "    \n",
    "    # Row 1: Ground truth for each class (each channel)\n",
    "    for j in range(n_classes):\n",
    "        axs[1, j].imshow(gt_mask[j], cmap='viridis')\n",
    "        axs[1, j].set_title(f\"GT: {class_names[j]}\")\n",
    "        axs[1, j].axis('off')\n",
    "    \n",
    "    # Row 2: Predictions for each class (each channel)\n",
    "    for j in range(n_classes):\n",
    "        axs[2, j].imshow(pred_mask[j], cmap='viridis')\n",
    "        axs[2, j].set_title(f\"Pred: {class_names[j]}\")\n",
    "        axs[2, j].axis('off')\n",
    "    \n",
    "    fig.suptitle(\"Retrained Model Prediction\", fontsize=16)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59f2288",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b03596da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mojas-sanghi\u001b[0m (\u001b[33mojas-sanghi-university-of-arizona\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nrjost/githome/pvcracks/retrain/training/wandb/run-20250609_144013-xs8lwdiv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ojas-sanghi-university-of-arizona/pvcracks/runs/xs8lwdiv' target=\"_blank\">polar-planet-322</a></strong> to <a href='https://wandb.ai/ojas-sanghi-university-of-arizona/pvcracks' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ojas-sanghi-university-of-arizona/pvcracks' target=\"_blank\">https://wandb.ai/ojas-sanghi-university-of-arizona/pvcracks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ojas-sanghi-university-of-arizona/pvcracks/runs/xs8lwdiv' target=\"_blank\">https://wandb.ai/ojas-sanghi-university-of-arizona/pvcracks/runs/xs8lwdiv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_name = \"model.pt\"\n",
    "save_dir = get_save_dir(str(root), checkpoint_name)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "original_config = {\n",
    "    \"batch_size_train\": 32,\n",
    "    \"lr\": 0.00092234,#wandb run: playful-shape-234 #0.00092234,\n",
    "    \"gamma\": 0.11727,#wandb #0.11727,\n",
    "    \"num_epochs\": 45,#wandb\n",
    "    \n",
    "    # constants\n",
    "    \"batch_size_test\": 32, #check VAE \n",
    "    \"criterion\": torch.nn.BCEWithLogitsLoss(),\n",
    "    \"k_folds\": 5,\n",
    "    # \"lr_scheduler_step_size\": 1,\n",
    "}\n",
    "\n",
    "config_serializable = original_config.copy()\n",
    "config_serializable[\"criterion\"] = str(config_serializable[\"criterion\"])\n",
    "\n",
    "with open(os.path.join(save_dir, \"config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(config_serializable, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"pvcracks\",\n",
    "    entity=\"ojas-sanghi-university-of-arizona\",\n",
    "    config=original_config,\n",
    ")\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f5b95ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=config.batch_size_train, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=config.batch_size_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "899b8831-e729-42c3-9eae-703af3d3001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=config.lr)\n",
    "\n",
    "# log gradients\n",
    "run.watch(model, log_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0b5a33b-f614-4c09-af94-1ab3de3f189d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/45 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 29.81 MiB is free. Process 3697407 has 34.73 GiB memory in use. Including non-PyTorch memory, this process has 4.72 GiB memory in use. Of the allocated memory 4.22 GiB is allocated by PyTorch, and 21.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m output \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# calc loss -- bce with logits loss applies sigmoid interally\u001b[39;00m\n\u001b[1;32m     21\u001b[0m training_loss \u001b[38;5;241m=\u001b[39m original_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m\"\u001b[39m](output, target)\n",
      "File \u001b[0;32m~/anaconda3/envs/pyhpc_torcha3/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/pyhpc_torcha3/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/githome/pvcracks/retrain/training/tutorials/unet_model.py:115\u001b[0m, in \u001b[0;36mUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    113\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m encoder_block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_blocks:\n\u001b[0;32m--> 115\u001b[0m     x \u001b[38;5;241m=\u001b[39m encoder_block(x)\n\u001b[1;32m    116\u001b[0m     encoder_outputs\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m    117\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbottle(encoder_outputs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/pyhpc_torcha3/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/pyhpc_torcha3/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/pyhpc_torcha3/lib/python3.13/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/pyhpc_torcha3/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/pyhpc_torcha3/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/pyhpc_torcha3/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py:193\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    186\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    202\u001b[0m     bn_training,\n\u001b[1;32m    203\u001b[0m     exponential_average_factor,\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps,\n\u001b[1;32m    205\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/pyhpc_torcha3/lib/python3.13/site-packages/torch/nn/functional.py:2822\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2820\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2822\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m   2823\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2824\u001b[0m     weight,\n\u001b[1;32m   2825\u001b[0m     bias,\n\u001b[1;32m   2826\u001b[0m     running_mean,\n\u001b[1;32m   2827\u001b[0m     running_var,\n\u001b[1;32m   2828\u001b[0m     training,\n\u001b[1;32m   2829\u001b[0m     momentum,\n\u001b[1;32m   2830\u001b[0m     eps,\n\u001b[1;32m   2831\u001b[0m     torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled,\n\u001b[1;32m   2832\u001b[0m )\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 29.81 MiB is free. Process 3697407 has 34.73 GiB memory in use. Including non-PyTorch memory, this process has 4.72 GiB memory in use. Of the allocated memory 4.22 GiB is allocated by PyTorch, and 21.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "training_epoch_loss = []\n",
    "test_epoch_loss = []\n",
    "test_dice_loss = []\n",
    "test_iou_loss = []\n",
    "\n",
    "best_epoch_test_loss = float(\"inf\")\n",
    "best_epoch_dice = 0.0\n",
    "best_epoch_iou = 0.0\n",
    "\n",
    "for epoch in tqdm(range(1, config.num_epochs + 1)):\n",
    "    \n",
    "    training_step_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        target = target.float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        output = model(data)\n",
    "        # calc loss -- bce with logits loss applies sigmoid interally\n",
    "        training_loss = original_config[\"criterion\"](output, target)\n",
    "        #backward pass\n",
    "        training_loss.backward()\n",
    "        optimizer.step()\n",
    "        # record loss\n",
    "        training_step_loss.append(training_loss.item())\n",
    "        \n",
    "    test_step_loss = []\n",
    "    dice_scores = []\n",
    "    iou_scores = []\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        target = target.float()\n",
    "        # forward pass\n",
    "        # data = data.to(device)\n",
    "        output = model(data)\n",
    "        \n",
    "        # calc loss -- bce with logits loss applies sigmoid interally\n",
    "        test_loss = original_config[\"criterion\"](output, target)\n",
    "        test_step_loss.append(test_loss.item())\n",
    "        \n",
    "        # compute dice and iou\n",
    "        pred_probs = torch.sigmoid(output)\n",
    "        pred_binary = (pred_probs > 0.5).float()\n",
    "        for i in range(pred_binary.size(1)):\n",
    "            dice = dice_coefficient(pred_binary[:, i], target[:, i])\n",
    "            iou = iou_score(pred_binary[:, i], target[:, i])\n",
    "            dice_scores.append(dice.item())\n",
    "            iou_scores.append(iou.item())\n",
    "        \n",
    "    epoch_train_loss = np.mean(training_step_loss)\n",
    "    epoch_test_loss = np.mean(test_step_loss)\n",
    "    epoch_avg_dice = np.mean(dice_scores)\n",
    "    epoch_avg_iou = np.mean(iou_scores)\n",
    "    \n",
    "    training_epoch_loss.append(epoch_train_loss)\n",
    "    test_epoch_loss.append(epoch_test_loss)\n",
    "    test_dice_loss.append(epoch_avg_dice)\n",
    "    test_iou_loss.append(epoch_avg_iou)\n",
    "    \n",
    "    run.log({\n",
    "        \"train_loss\": epoch_train_loss,\n",
    "        \"test_loss\": epoch_test_loss,\n",
    "        \"avg_dice\": epoch_avg_dice,\n",
    "        \"avg_iou\": epoch_avg_iou,\n",
    "    }, step=epoch)\n",
    "    \n",
    "    \n",
    "    if epoch_test_loss < best_epoch_test_loss:\n",
    "        best_epoch_test_loss = epoch_test_loss\n",
    "        best_epoch_dice = epoch_avg_dice\n",
    "        best_epoch_iou = epoch_avg_iou\n",
    "        \n",
    "        os.makedirs(os.path.join(save_dir, f'epoch_{epoch}'), exist_ok=True)\n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, f'epoch_{epoch}', save_name))\n",
    "        print(f'Saved model at epoch {epoch}')\n",
    "\n",
    "    print(f\"Epoch {epoch} best test_loss: {best_epoch_test_loss:.4f}, dice: {best_epoch_dice:.4f}, iou: {best_epoch_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e08d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4951b028",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_inference_and_show(-32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db3cb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_inference_and_show(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32576c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_inference_and_show(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6c084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_inference_and_show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8933f766",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_inference_and_show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05de89ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     new_inference_and_show(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4a9bfe-7b09-4a7a-8718-fc779cb8b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = np.arange(1, len(training_epoch_loss) + 1, 1)\n",
    "\n",
    "ax.scatter(x, training_epoch_loss, label='training loss')\n",
    "ax.scatter(x, test_epoch_loss, label='test loss')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Epoch')\n",
    "\n",
    "print(training_epoch_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4646dffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyhpc_torcha3",
   "language": "python",
   "name": "pyhpc_torcha3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
